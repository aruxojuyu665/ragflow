---
sidebar_position: 10
slug: /faq
---

# Часто задаваемые вопросы

Ответы на вопросы о общих функциях, устранении неполадок, использовании и многое другое.

---

import TOCInline from '@theme/TOCInline';

<TOCInline toc={toc} />

## Общие функции

---

### Чем RAGFlow отличается от других продуктов RAG?

Статус-кво «garbage in, garbage out» (мусор на входе — мусор на выходе) остается неизменным, несмотря на значительный прогресс LLM в области Natural Language Processing (NLP, обработка естественного языка). В своих ответах RAGFlow предлагает две уникальные функции по сравнению с другими продуктами Retrieval-Augmented Generation (RAG, генерация с дополнением извлечением).

- Тонкий разбор документов: разбор документов включает изображения и таблицы с возможностью вашего вмешательства при необходимости.
- Отслеживаемые ответы с уменьшением галлюцинаций: вы можете доверять ответам RAGFlow, так как видите цитаты и ссылки, их подтверждающие.

---

### В чем разница между полной и облегчённой версиями RAGFlow?

Каждый релиз RAGFlow доступен в двух редакциях:

- **Slim edition (облегчённая версия)**: не включает встроенные embedding модели и обозначается суффиксом **-slim** в названии версии. Пример: `infiniflow/ragflow:v0.21.1-slim`
- **Full edition (полная версия)**: включает встроенные embedding модели и не имеет суффикса в названии версии. Пример: `infiniflow/ragflow:v0.21.1`

Примечание: начиная с версии `v0.22.0`, мы поставляем только облегчённую версию и больше не добавляем суффикс **-slim** к тегу образа.

---

### Какие embedding модели можно развернуть локально?

RAGFlow предлагает два варианта Docker-образов: `v0.21.1-slim` и `v0.21.1`:  
  
- `infiniflow/ragflow:v0.21.1-slim` (по умолчанию): Docker-образ RAGFlow без embedding моделей.  
- `infiniflow/ragflow:v0.21.1`: Docker-образ RAGFlow с встроенными embedding моделями:
  - `BAAI/bge-large-zh-v1.5`
  - `maidalun1020/bce-embedding-base_v1`

Примечание: начиная с версии `v0.22.0`, мы поставляем только облегчённую версию и больше не добавляем суффикс **-slim** к тегу образа.

---

### Где найти версию RAGFlow? Как её интерпретировать?

Версию RAGFlow можно найти на странице **System** в пользовательском интерфейсе:

![Изображение](https://github.com/user-attachments/assets/20cf7213-2537-4e18-a88c-4dadf6228c6b)

Если вы собираете RAGFlow из исходников, номер версии также отображается в системном логе:

```
        ____   ___    ______ ______ __               
       / __ \ /   |  / ____// ____// /____  _      __
      / /_/ // /| | / / __ / /_   / // __ \| | /| / /
     / _, _// ___ |/ /_/ // __/  / // /_/ /| |/ |/ / 
    /_/ |_|/_/  |_|\____//_/    /_/ \____/ |__/|__/                             

2025-02-18 10:10:43,835 INFO     1445658 RAGFlow version: v0.15.0-50-g6daae7f2 full
```

Где:

- `v0.15.0`: официально опубликованный релиз.
- `50`: количество коммитов git с момента официального релиза.
- `g6daae7f2`: `g` — префикс, а `6daae7f2` — первые семь символов текущего ID коммита.
- `full`/`slim`: редакция RAGFlow.
  - `full`: полная редакция RAGFlow.
  - `slim`: редакция RAGFlow без embedding моделей и Python-пакетов.

---

### Почему не использовать другие open-source векторные базы данных в качестве движка документов?

В настоящее время только Elasticsearch и [Infinity](https://github.com/infiniflow/infinity) соответствуют требованиям гибридного поиска RAGFlow. Большинство open-source векторных баз данных имеют ограниченную поддержку полнотекстового поиска, а разреженное embedding не является альтернативой полнотекстовому поиску. Кроме того, эти векторные базы данных не обладают критически важными для RAGFlow функциями, такими как поиск по фразам и расширенные возможности ранжирования.

Эти ограничения побудили нас разработать [Infinity](https://github.com/infiniflow/infinity) — AI-native базу данных с нуля.

---

### В чем разница между demo.ragflow.io и локально развернутым open-source сервисом RAGFlow?

demo.ragflow.io демонстрирует возможности RAGFlow Enterprise. Его DeepDoc модели предварительно обучены на проприетарных данных, а также предоставляют более продвинутые механизмы управления разрешениями для команд. По сути, demo.ragflow.io служит превью будущего SaaS (Software as a Service) предложения RAGFlow.

Вы можете развернуть open-source сервис RAGFlow и вызывать его из Python клиента или через RESTful API. Однако это не поддерживается на demo.ragflow.io.

---

### Почему RAGFlow дольше парсит документы, чем LangChain?

Мы уделяем большое внимание задачам предварительной обработки документов, таким как анализ макета, распознавание структуры таблиц и OCR (Optical Character Recognition, оптическое распознавание символов) с использованием наших vision моделей. Это увеличивает время обработки.

---

### Почему RAGFlow требует больше ресурсов, чем другие проекты?

RAGFlow включает множество встроенных моделей для парсинга структуры документов, что требует дополнительных вычислительных ресурсов.

---

### Какие архитектуры или устройства поддерживает RAGFlow?

Мы официально поддерживаем x86 CPU и nvidia GPU. Хотя мы также тестируем RAGFlow на платформах ARM64, Docker-образы RAGFlow для ARM не поддерживаются. Если вы используете ARM-платформу, следуйте [этому руководству](./develop/build_docker_image.mdx) для сборки Docker-образа RAGFlow.

---

### Предлагаете ли вы API для интеграции с приложениями третьих сторон?

Соответствующие API уже доступны. См. [RAGFlow HTTP API Reference](./references/http_api_reference.md) или [RAGFlow Python API Reference](./references/python_api_reference.md) для подробностей.

---

### Поддерживается ли потоковый вывод?

Да, поддерживается. Потоковый вывод включён по умолчанию в чат-ассистенте и агенте. Обратите внимание, что отключить потоковый вывод через UI RAGFlow нельзя. Чтобы отключить потоковый вывод в ответах, используйте Python или RESTful API RAGFlow:

Python:

- [Create chat completion](./references/python_api_reference.md#create-chat-completion)
- [Converse with chat assistant](./references/python_api_reference.md#converse-with-chat-assistant)
- [Converse with agent](./references/python_api_reference.md#converse-with-agent)

RESTful:

- [Create chat completion](./references/http_api_reference.md#create-chat-completion)
- [Converse with chat assistant](./references/http_api_reference.md#converse-with-chat-assistant)
- [Converse with agent](./references/http_api_reference.md#converse-with-agent)

---

### Поддерживается ли обмен диалогом через URL?

Нет, эта функция не поддерживается.

---

### Поддерживается ли многократный диалог с использованием предыдущих сообщений как контекста для текущего запроса?

Да, мы поддерживаем улучшение пользовательских запросов на основе существующего контекста текущего разговора:

1. На странице **Chat** наведите курсор на нужного ассистента и выберите **Edit**.
2. В всплывающем окне **Chat Configuration** перейдите на вкладку **Prompt engine**.
3. Включите опцию **Multi-turn optimization** для активации этой функции.

---

### Ключевые отличия между AI поиском и чатом?

- **AI search (AI поиск)**: это однократный AI диалог с использованием предопределённой стратегии извлечения (гибридный поиск с взвешенной схожестью ключевых слов и векторов) и системной модели чата по умолчанию. Не используются продвинутые RAG стратегии, такие как knowledge graph, auto-keyword или auto-question. Извлечённые фрагменты отображаются под ответом модели чата.
- **AI chat (AI чат)**: это многошаговый AI диалог, где вы можете определить стратегию извлечения (взвешенный reranking score может заменить взвешенную векторную схожесть в гибридном поиске) и выбрать модель чата. В AI чате можно настроить продвинутые RAG стратегии, такие как knowledge graph, auto-keyword и auto-question, для конкретного случая. Извлечённые фрагменты не отображаются вместе с ответом.

При отладке чат-ассистента вы можете использовать AI поиск как эталон для проверки настроек модели и стратегии извлечения.

---

## Устранение неполадок

---

### Как собрать Docker-образ RAGFlow с нуля?

См. [Build a RAGFlow Docker image](./develop/build_docker_image.mdx).

### Не удаётся получить доступ к https://huggingface.co

Локально развернутый RAGFlow по умолчанию загружает OCR и embedding модули с сайта [Huggingface](https://huggingface.co). Если ваш компьютер не может получить доступ к этому сайту, возникает следующая ошибка, и парсинг PDF не выполняется:

```
FileNotFoundError: [Errno 2] No such file or directory: '/root/.cache/huggingface/hub/models--InfiniFlow--deepdoc/snapshots/be0c1e50eef6047b412d1800aa89aba4d275f997/ocr.res'
```

Для решения используйте https://hf-mirror.com:

1. Остановите все контейнеры и удалите все связанные ресурсы:

   ```bash
   cd ragflow/docker/
   docker compose down
   ```

2. Раскомментируйте следующую строку в файле **ragflow/docker/.env**:

   ```
   # HF_ENDPOINT=https://hf-mirror.com
   ```

3. Запустите сервер:

   ```bash
   docker compose up -d 
   ```

---

### `MaxRetryError: HTTPSConnectionPool(host='hf-mirror.com', port=443)`

Эта ошибка указывает на отсутствие доступа в Интернет или невозможность подключения к hf-mirror.com. Попробуйте следующее:

1. Скачайте вручную файлы ресурсов с [huggingface.co/InfiniFlow/deepdoc](https://huggingface.co/InfiniFlow/deepdoc) в локальную папку **~/deepdoc**.
2. Добавьте volume в **docker-compose.yml**, например:

   ```
   - ~/deepdoc:/ragflow/rag/res/deepdoc
   ```

---

### `WARNING: can't find /raglof/rag/res/borker.tm`

Игнорируйте это предупреждение и продолжайте работу. Все системные предупреждения можно игнорировать.

---

### `network anomaly There is an abnormality in your network and you cannot connect to the server.`

![аномалия](https://github.com/infiniflow/ragflow/assets/93570324/beb7ad10-92e4-4a58-8886-bfb7cbd09e5d)

Вы не сможете войти в RAGFlow, пока сервер полностью не инициализируется. Выполните команду `docker logs -f docker-ragflow-cpu-1`.

*Сервер успешно инициализирован, если в системе отображается следующее:*

```
     ____   ___    ______ ______ __               
    / __ \ /   |  / ____// ____// /____  _      __
   / /_/ // /| | / / __ / /_   / // __ \| | /| / /
  / _, _// ___ |/ /_/ // __/  / // /_/ /| |/ |/ / 
 /_/ |_|/_/  |_|\____//_/    /_/ \____/ |__/|__/  

 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:9380
 * Running on http://x.x.x.x:9380
 INFO:werkzeug:Press CTRL+C to quit
```

---

### `Realtime synonym is disabled, since no redis connection`

Игнорируйте это предупреждение и продолжайте работу. Все системные предупреждения можно игнорировать.

![](https://github.com/infiniflow/ragflow/assets/93570324/ef5a6194-084a-4fe3-bdd5-1c025b40865c)

---

### Почему парсинг документа останавливается на значении меньше одного процента?

![зависание](https://github.com/infiniflow/ragflow/assets/93570324/3589cc25-c733-47d5-bbfc-fedb74a3da50)

Нажмите на красный крестик рядом с индикатором «parsing status», затем перезапустите процесс парсинга, чтобы проверить, сохраняется ли проблема. Если проблема не исчезает и RAGFlow развернут локально, попробуйте следующее:

1. Проверьте логи сервера RAGFlow, чтобы убедиться, что он работает корректно:

   ```bash
   docker logs -f docker-ragflow-cpu-1
   ```

2. Проверьте, существует ли процесс **task_executor.py**.
3. Проверьте, может ли сервер RAGFlow получить доступ к hf-mirror.com или huggingface.com.

---

### Почему парсинг PDF останавливается почти у завершения, при этом в логе нет ошибок?

Нажмите на красный крестик рядом с индикатором «parsing status», затем перезапустите процесс парсинга, чтобы проверить, сохраняется ли проблема. Если проблема не исчезает и RAGFlow развернут локально, вероятно, процесс парсинга завершился из-за недостатка оперативной памяти. Попробуйте увеличить выделение памяти, увеличив значение `MEM_LIMIT` в файле **docker/.env**.

:::note
Убедитесь, что вы перезапустили сервер RAGFlow, чтобы изменения вступили в силу!

```bash
docker compose stop
```

```bash
docker compose up -d
```

:::

![почти завершено](https://github.com/infiniflow/ragflow/assets/93570324/563974c3-f8bb-4ec8-b241-adcda8929cbb)

---

### `Index failure`

Ошибка индекса обычно указывает на недоступность сервиса Elasticsearch.

---

### Как проверить логи RAGFlow?

```bash
tail -f ragflow/docker/ragflow-logs/*.log
```

---

### Как проверить статус каждого компонента RAGFlow?

1. Проверьте статус Docker-контейнера Elasticsearch:

   ```bash
   $ docker ps
   ```

   *Пример результата:*

   ```bash
   5bc45806b680   infiniflow/ragflow:latest     "./entrypoint.sh"        11 hours ago   Up 11 hours               0.0.0.0:80->80/tcp, :::80->80/tcp, 0.0.0.0:443->443/tcp, :::443->443/tcp, 0.0.0.0:9380->9380/tcp, :::9380->9380/tcp   docker-ragflow-cpu-1
   91220e3285dd   docker.elastic.co/elasticsearch/elasticsearch:8.11.3   "/bin/tini -- /usr/l…"   11 hours ago   Up 11 hours (healthy)     9300/tcp, 0.0.0.0:9200->9200/tcp, :::9200->9200/tcp           ragflow-es-01
   d8c86f06c56b   mysql:5.7.18        "docker-entrypoint.s…"   7 days ago     Up 16 seconds (healthy)   0.0.0.0:3306->3306/tcp, :::3306->3306/tcp     ragflow-mysql
   cd29bcb254bc   quay.io/minio/minio:RELEASE.2023-12-20T01-00-02Z       "/usr/bin/docker-ent…"   2 weeks ago    Up 11 hours      0.0.0.0:9001->9001/tcp, :::9001->9001/tcp, 0.0.0.0:9000->9000/tcp, :::9000->9000/tcp     ragflow-minio
   ```

2. Следуйте [этому документу](./guides/run_health_check.md) для проверки состояния здоровья сервиса Elasticsearch.

:::danger ВАЖНО
Статус Docker-контейнера не обязательно отражает состояние сервиса. Вы можете обнаружить, что сервисы не работают корректно, даже если соответствующие контейнеры запущены. Возможные причины — проблемы с сетью, неправильные номера портов или DNS.
:::

---

### `Exception: Can't connect to ES cluster`

1. Проверьте статус Docker-контейнера Elasticsearch:

   ```bash
   $ docker ps
   ```

   *Статус здорового компонента Elasticsearch должен выглядеть так:*  

   ```
   91220e3285dd   docker.elastic.co/elasticsearch/elasticsearch:8.11.3   "/bin/tini -- /usr/l…"   11 hours ago   Up 11 hours (healthy)     9300/tcp, 0.0.0.0:9200->9200/tcp, :::9200->9200/tcp           ragflow-es-01
   ```

2. Следуйте [этому документу](./guides/run_health_check.md) для проверки состояния здоровья сервиса Elasticsearch.

:::danger ВАЖНО
Статус Docker-контейнера не обязательно отражает состояние сервиса. Вы можете обнаружить, что сервисы не работают корректно, даже если соответствующие контейнеры запущены. Возможные причины — проблемы с сетью, неправильные номера портов или DNS.
:::

3. Если контейнер постоянно перезапускается, убедитесь, что `vm.max_map_count` >= 262144, как указано в [README](https://github.com/infiniflow/ragflow?tab=readme-ov-file#-start-up-the-server). Для постоянного изменения этого параметра обновите значение в **/etc/sysctl.conf**. Обратите внимание, что эта настройка работает только в Linux.

---

### Не удаётся запустить контейнер ES, появляется ошибка `Elasticsearch did not exit normally`

Это происходит из-за того, что вы забыли обновить значение `vm.max_map_count` в **/etc/sysctl.conf**, и после перезагрузки системы оно сбросилось.

---

### `{"data":null,"code":100,"message":"<NotFound '404: Not Found'>"}`

Возможно, ваш IP-адрес или номер порта указаны неверно. Если вы используете настройки по умолчанию, введите в браузере `http://<IP_ВАШЕЙ_МАШИНЫ>` (**БЕЗ 9380 и БЕЗ НОМЕРА ПОРТА!**). Это должно работать.

---

### `Ollama - Mistral instance running at 127.0.0.1:11434 but cannot add Ollama as model in RagFlow`

Правильный IP-адрес и порт Ollama критичны для добавления моделей в Ollama:

- Если вы используете demo.ragflow.io, убедитесь, что сервер Ollama имеет публичный доступный IP-адрес. Обратите внимание, что 127.0.0.1 — не публичный IP.
- Если вы развернули RAGFlow локально, убедитесь, что Ollama и RAGFlow находятся в одной локальной сети и могут взаимодействовать.

Подробнее см. [Deploy a local LLM](./guides/models/deploy_local_llm.mdx).

---

### Есть ли примеры использования DeepDoc для парсинга PDF или других файлов?

Да, есть. Смотрите Python-файлы в папке **rag/app**.

---

### `FileNotFoundError: [Errno 2] No such file or directory`

1. Проверьте статус Docker-контейнера MinIO:

   ```bash
   $ docker ps
   ```

   *Статус здорового компонента MinIO должен выглядеть так:*  

   ```bash
   cd29bcb254bc   quay.io/minio/minio:RELEASE.2023-12-20T01-00-02Z       "/usr/bin/docker-ent…"   2 weeks ago    Up 11 hours      0.0.0.0:9001->9001/tcp, :::9001->9001/tcp, 0.0.0.0:9000->9000/tcp, :::9000->9000/tcp     ragflow-minio
   ```

2. Следуйте [этому документу](./guides/run_health_check.md) для проверки состояния здоровья сервиса Elasticsearch.

:::danger ВАЖНО
Статус Docker-контейнера не обязательно отражает состояние сервиса. Вы можете обнаружить, что сервисы не работают корректно, даже если соответствующие контейнеры запущены. Возможные причины — проблемы с сетью, неправильные номера портов или DNS.
:::

---

## Использование

---

### Как запустить RAGFlow с локально развернутой LLM?

Вы можете использовать Ollama или Xinference для развертывания локальной LLM. Подробнее см. [здесь](./guides/models/deploy_local_llm.mdx).

---

### Как добавить LLM, которая не поддерживается?

Если ваша модель пока не поддерживается, но имеет API, совместимый с OpenAI, нажмите **OpenAI-API-Compatible** на странице **Model providers** для её настройки:

![openai-api-compatible](https://github.com/user-attachments/assets/b1e964f2-b86e-41af-8528-fd8a96dc5f6f)

---

### Как интегрировать RAGFlow с Ollama?

- Если RAGFlow развернут локально, убедитесь, что RAGFlow и Ollama находятся в одной локальной сети.
- Если вы используете онлайн-демо, убедитесь, что IP-адрес сервера Ollama публичный и доступный.

Подробнее см. [здесь](./guides/models/deploy_local_llm.mdx).

---

### Как изменить ограничение на размер файла?

Для локально развернутого RAGFlow: общий лимит размера файлов за одну загрузку — 1 ГБ, с ограничением пакетной загрузки до 32 файлов. Ограничения на общее количество файлов на аккаунт нет. Чтобы изменить лимит в 1 ГБ:

- В файле **docker/.env** раскомментируйте строку `# MAX_CONTENT_LENGTH=1073741824`, отредактируйте значение по необходимости (1073741824 — это 1 ГБ в байтах).
- Если вы изменяете `MAX_CONTENT_LENGTH` в **docker/.env**, убедитесь, что соответствующим образом обновили `client_max_body_size` в **nginx/nginx.conf**.

:::tip ПРИМЕЧАНИЕ
Не рекомендуется вручную менять лимит пакетной загрузки в 32 файла. Однако при загрузке файлов через HTTP API или Python SDK RAGFlow это ограничение автоматически снимается.
:::

---

### `Error: Range of input length should be [1, 30000]`

Эта ошибка возникает из-за слишком большого количества совпадающих фрагментов. Попробуйте уменьшить **TopN** и увеличить **Similarity threshold** для решения:

1. Нажмите **Chat** в верхней средней части страницы.
2. Кликните правой кнопкой по нужному разговору > **Edit** > **Prompt engine**
3. Уменьшите **TopN** и/или увеличьте **Similarity threshold**.
4. Нажмите **OK** для подтверждения изменений.

![topn](https://github.com/infiniflow/ragflow/assets/93570324/7ec72ab3-0dd2-4cff-af44-e2663b67b2fc)

---

### Как получить API-ключ для интеграции с приложениями третьих сторон?

См. [Acquire a RAGFlow API key](./develop/acquire_ragflow_api_key.md).

---

### Как обновить RAGFlow?

См. [Upgrade RAGFlow](./guides/upgrade_ragflow.mdx) для подробностей.

---

### Как переключить движок документов на Infinity?

Чтобы переключить движок документов с Elasticsearch на [Infinity](https://github.com/infiniflow/infinity):

1. Остановите все запущенные контейнеры:  

   ```bash
   $ docker compose -f docker/docker-compose.yml down -v
   ```
:::caution ВНИМАНИЕ
Опция `-v` удалит все тома Docker-контейнеров, и существующие данные будут очищены.
:::

2. В файле **docker/.env** установите `DOC_ENGINE=${DOC_ENGINE:-infinity}`
3. Перезапустите Docker-образ: 

   ```bash
   $ docker compose -f docker-compose.yml up -d
   ```

---

### Где хранятся загруженные файлы в образе RAGFlow?

Все загруженные файлы хранятся в Minio — объектном хранилище RAGFlow. Например, если вы загружаете файл напрямую в датасет, он находится по пути `<knowledgebase_id>/filename`.

---

### Как настроить размер пакета для парсинга и embedding документов?

Вы можете контролировать размер пакета для парсинга и embedding, задавая переменные окружения `DOC_BULK_SIZE` и `EMBEDDING_BATCH_SIZE`. Увеличение этих значений может повысить пропускную способность при обработке больших объёмов данных, но увеличит потребление памяти. Настраивайте их в соответствии с ресурсами вашего оборудования.

---

### Как ускорить скорость ответов на вопросы в моём чат-ассистенте?

См. [здесь](./guides/chat/best_practices/accelerate_question_answering.mdx).

---

### Как ускорить скорость ответов на вопросы в моём Агенте?

См. [здесь](./guides/agent/best_practices/accelerate_agent_question_answering.md).

---

### Как использовать MinerU для парсинга PDF документов?

Парсинг PDF документов с помощью MinerU доступен начиная с версии v0.21.1. Для использования выполните следующие шаги:

1. Перед развертыванием ragflow-server обновите файл **docker/.env**:  
   - Включите `HF_ENDPOINT=https://hf-mirror.com`
   - Добавьте запись MinerU: `MINERU_EXECUTABLE=/ragflow/uv_tools/.venv/bin/mineru`

2. Запустите ragflow-server и выполните следующие команды внутри контейнера:  

```bash
mkdir uv_tools
cd uv_tools
uv venv .venv
source .venv/bin/activate
uv pip install -U "mineru[core]" -i https://mirrors.aliyun.com/pypi/simple
```

3. Перезапустите ragflow-server.
4. В веб-интерфейсе перейдите на страницу **Configuration** вашего датасета. В разделе **Ingestion pipeline** нажмите **Built-in**, выберите метод разбиения из выпадающего списка **Built-in**, который поддерживает парсинг PDF, и выберите **MinerU** в поле **PDF parser**.
5. Если вы используете кастомный ingestion pipeline, сначала выполните первые три шага, затем выберите **MinerU** в разделе **Parsing method** компонента **Parser**.

---

### Как настроить параметры, специфичные для MinerU?

1. Задайте `MINERU_EXECUTABLE` (по умолчанию: `mineru`) — путь к исполняемому файлу MinerU.
2. Установите `MINERU_DELETE_OUTPUT` в `0`, чтобы сохранить вывод MinerU. (По умолчанию: `1` — удалять временный вывод)
3. Установите `MINERU_OUTPUT_DIR` для указания каталога вывода MinerU.
4. Установите `MINERU_BACKEND` в `"pipeline"`. (Опции: `"pipeline"` (по умолчанию) | `"vlm-transformers"`)

:::tip ПРИМЕЧАНИЕ
Информацию о других переменных окружения, нативно поддерживаемых MinerU, смотрите [здесь](https://opendatalab.github.io/MinerU/usage/cli_tools/#environment-variables-description).
:::